{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YYk8NG3yOIT9"
   },
   "source": [
    "### A MNIST-like fashion product database\n",
    "\n",
    "In this, we classify the images into respective classes given in the dataset. We use a Neural Net and a Deep Neural Net in Keras to solve this and check the accuracy scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tFO6PuxzOIT_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Load tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, BatchNormalization, Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.13.1\n"
     ]
    }
   ],
   "source": [
    "tf.set_random_seed(42)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HcoZBStrOIUQ",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Collect Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qnbx7TyQOIUY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
      "32768/29515 [=================================] - 0s 3us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
      "26427392/26421880 [==============================] - 18s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
      "8192/5148 [===============================================] - 0s 1us/step\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
      "4423680/4422102 [==============================] - 3s 1us/step\n"
     ]
    }
   ],
   "source": [
    "(trainX, trainY), (testX, testY) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UbiHj5YPOIUc",
    "outputId": "87e1b9cd-07f0-45cb-e706-0d51ad742d72",
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9 2 1 1 6]\n"
     ]
    }
   ],
   "source": [
    "print(testY[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainX shape: (60000, 28, 28)\n",
      "testX shape: (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(\"trainX shape:\", trainX.shape)\n",
    "print(\"testX shape:\",testX.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FwhQ8e7VOIUw"
   },
   "source": [
    "### Visualize the data\n",
    "\n",
    "Plot first 10 images in the triaining set and their labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label for each of the above image:\n",
      "9 0 0 3 0 2 7 2 5 5 "
     ]
    }
   ],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "for i in range(10):\n",
    "    plt.subplot(10,10,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    plt.imshow(trainX[i], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "\n",
    "print(\"label for each of the above image:\")\n",
    "for i in range(10):\n",
    "    print(trainY[i], end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lDAYzkwyOIUj",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Convert both training and testing labels into one-hot vectors.\n",
    "\n",
    "**Hint:** check **tf.keras.utils.to_categorical()**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data to the range of [0, 1]\n",
    "trainX = trainX.astype(\"float32\") / 255.0\n",
    "testX = testX.astype(\"float32\") / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "vBlfYlANOIUk"
   },
   "outputs": [],
   "source": [
    "# one-hot encode the training and testing labels\n",
    "trainY = tf.keras.utils.to_categorical(trainY, 10)\n",
    "testY = tf.keras.utils.to_categorical(testY, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RHV3b9mzOIUq",
    "outputId": "27bdfe58-91ee-4677-fe49-e742ad306c70",
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 10)\n",
      "First 5 examples now are:  [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "print(trainY.shape)\n",
    "print('First 5 examples now are: ', trainY[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "l4TbJGeSOIU4",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build a neural Network with a cross entropy loss function and sgd optimizer in Keras. The output layer with 10 neurons as we have 10 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 8)                 6280      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 6,370\n",
      "Trainable params: 6,370\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[ 0.07242958, -0.0172141 , -0.03660319, ..., -0.04176918,\n",
       "         -0.01488733, -0.03945194],\n",
       "        [-0.04472928, -0.0820328 ,  0.03662797, ...,  0.00359751,\n",
       "         -0.01530733, -0.0632304 ],\n",
       "        [-0.0149691 ,  0.06567623,  0.03532644, ..., -0.00788277,\n",
       "          0.05714293,  0.01235604],\n",
       "        ...,\n",
       "        [-0.02548972,  0.08018591,  0.02042529, ..., -0.03719877,\n",
       "          0.0571906 , -0.05991714],\n",
       "        [-0.02207696, -0.05321024, -0.03393735, ...,  0.08389965,\n",
       "         -0.05338563,  0.07023734],\n",
       "        [ 0.05492991,  0.03209713,  0.07112564, ...,  0.06084995,\n",
       "         -0.06933644,  0.03344721]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 0.52333164, -0.15180266, -0.30260307, -0.06977791,  0.43044686,\n",
       "         -0.25397757, -0.40847284, -0.28774887, -0.34237528,  0.31167442],\n",
       "        [-0.35719794,  0.19658643, -0.3188448 , -0.2540314 , -0.3697567 ,\n",
       "         -0.16196969, -0.5158603 , -0.48513138, -0.00462246, -0.28986388],\n",
       "        [ 0.17307073,  0.21329892,  0.1475988 , -0.15576619,  0.23299378,\n",
       "         -0.31874198,  0.50110805, -0.01447439,  0.5118307 , -0.19150808],\n",
       "        [-0.39823323,  0.3091824 , -0.12809983,  0.40352923,  0.13013154,\n",
       "          0.23563075,  0.37484676,  0.05916917,  0.4045459 , -0.10791194],\n",
       "        [ 0.18359071,  0.27464503,  0.26943314, -0.30322415, -0.07308418,\n",
       "          0.54997325,  0.36586118, -0.34779364, -0.2923233 , -0.16040447],\n",
       "        [ 0.4580679 ,  0.5630239 ,  0.21987236,  0.31602168, -0.41863477,\n",
       "         -0.07017589, -0.25186354,  0.15009993, -0.3815462 , -0.06243646],\n",
       "        [ 0.28297818,  0.5272409 , -0.13834837,  0.24016774, -0.4501183 ,\n",
       "         -0.06552219,  0.41275418, -0.4047488 ,  0.5669111 , -0.29906586],\n",
       "        [ 0.4893719 ,  0.5242555 , -0.16774169,  0.25758213, -0.2316258 ,\n",
       "         -0.22197303,  0.27729082,  0.4525875 ,  0.12647307, -0.28441978]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3hQpLv3aOIU_",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model using model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 4s 65us/sample - loss: 0.3496 - acc: 0.8926\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 70us/sample - loss: 0.2754 - acc: 0.9018\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 4s 66us/sample - loss: 0.2205 - acc: 0.9160\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 59us/sample - loss: 0.1855 - acc: 0.9326\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 60us/sample - loss: 0.1660 - acc: 0.9372\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2793a802f28>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4.51266766e-04 1.04176998e-03 1.03775859e-02 1.01357102e-02\n",
      "  2.56969035e-02 2.34445781e-01 1.74278021e-03 3.55248511e-01\n",
      "  5.47741055e-02 4.93590325e-01]\n",
      " [5.09092212e-03 2.10076571e-04 5.61530650e-01 6.12437725e-05\n",
      "  2.73799717e-01 4.78699803e-03 9.96858478e-02 2.08616257e-07\n",
      "  1.71539187e-03 8.00281763e-04]\n",
      " [1.59397125e-02 9.41671968e-01 6.48292899e-03 1.20931447e-01\n",
      "  2.65270472e-03 4.63694334e-04 3.77630293e-02 1.59963965e-03\n",
      "  4.86198068e-03 3.29911709e-05]\n",
      " [5.58568537e-02 8.38289380e-01 1.38514936e-02 2.21086651e-01\n",
      "  1.72274709e-02 2.72443891e-03 4.65850234e-02 1.21650100e-02\n",
      "  5.61431050e-03 1.43918395e-03]\n",
      " [5.94200492e-02 1.07329190e-02 1.83283240e-01 7.16802478e-03\n",
      "  8.50428343e-02 6.70713186e-03 1.16461635e-01 4.79221344e-05\n",
      "  1.68414712e-02 3.97297740e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(pred[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(pred[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 51us/sample - loss: 0.1614 - acc: 0.9380\n",
      "Test loss: 0.16, test accuracy: 93.8%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(testX, testY)\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JdzDtGwDOIVF",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### In the above Neural Network model add Batch Normalization layer after the input layer and repeat the steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Add an BatchNormalization layer \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1 (Batc (None, 784)               3136      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 8)                 6280      \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                90        \n",
      "=================================================================\n",
      "Total params: 9,506\n",
      "Trainable params: 7,938\n",
      "Non-trainable params: 1,568\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0.], dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1.], dtype=float32),\n",
       " array([[ 0.04793765,  0.03127402, -0.03782997, ...,  0.00387175,\n",
       "         -0.06025765,  0.05522145],\n",
       "        [-0.05845384,  0.02457092, -0.07082887, ..., -0.02309128,\n",
       "         -0.03329569,  0.02672687],\n",
       "        [ 0.04887633,  0.0484952 , -0.02813109, ...,  0.04945591,\n",
       "          0.01039437, -0.03961333],\n",
       "        ...,\n",
       "        [ 0.00505392, -0.0542306 , -0.0832521 , ..., -0.04260173,\n",
       "          0.00807332, -0.01397005],\n",
       "        [-0.00366607,  0.03573096, -0.03432076, ...,  0.02143774,\n",
       "          0.06114911,  0.07017201],\n",
       "        [-0.05489725,  0.00437738, -0.07370356, ..., -0.03736015,\n",
       "          0.07264242,  0.06214136]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([[ 4.3552363e-01, -2.3553991e-01, -4.6192560e-01,  2.7727765e-01,\n",
       "         -9.1059446e-02, -5.0119925e-01,  1.6453058e-01,  8.6286962e-02,\n",
       "          6.6611648e-02,  1.8316108e-01],\n",
       "        [ 5.1413441e-01, -3.0728334e-01, -8.5939944e-02, -5.0990003e-01,\n",
       "          5.1374710e-01,  4.9548578e-01,  3.6286849e-01,  4.0158033e-01,\n",
       "         -3.3466434e-01, -1.0371041e-01],\n",
       "        [ 5.2184045e-01,  3.4128851e-01,  5.3662658e-01,  1.4498824e-01,\n",
       "          8.5514188e-03,  1.8848914e-01,  1.1779046e-01, -5.4431635e-01,\n",
       "          3.0182284e-01,  4.8452556e-01],\n",
       "        [ 4.6770835e-01,  1.4655662e-01, -4.6934873e-01,  1.1515856e-01,\n",
       "          7.4714899e-02,  6.9606841e-02, -3.4438235e-01,  1.5942496e-01,\n",
       "         -4.3213367e-02,  9.4681323e-02],\n",
       "        [-3.5791606e-01,  1.7181420e-01, -3.8934773e-01, -2.0536184e-03,\n",
       "          1.3034302e-01,  2.3454428e-04, -3.2608140e-01,  1.3764977e-02,\n",
       "         -4.6902370e-01, -4.7905654e-01],\n",
       "        [ 2.0170790e-01,  2.9104394e-01, -1.2847713e-01, -2.0041534e-01,\n",
       "         -9.5054090e-02, -3.0619052e-01, -1.2320882e-01,  3.1787461e-01,\n",
       "          5.0612152e-01, -3.3410355e-01],\n",
       "        [-6.6005349e-02, -2.4512193e-01,  3.3274561e-01, -1.1752576e-01,\n",
       "          3.7047148e-02,  3.4260511e-02,  4.4403815e-01,  3.5649884e-01,\n",
       "         -4.3830165e-01,  4.1854846e-01],\n",
       "        [-2.7696556e-01,  2.4996889e-01,  8.5576177e-03, -3.5968006e-01,\n",
       "         -2.7905485e-01,  5.7061970e-02,  9.8343492e-03, -8.0671638e-02,\n",
       "         -1.7359212e-01,  2.2334039e-02]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 5s 76us/sample - loss: 0.3582 - acc: 0.8581\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 4s 75us/sample - loss: 0.1715 - acc: 0.9361\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 82us/sample - loss: 0.1439 - acc: 0.9435\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 4s 73us/sample - loss: 0.1312 - acc: 0.9493\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 4s 69us/sample - loss: 0.1231 - acc: 0.9528\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2793ad32828>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(trainX, trainY, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mwk3T5LJOIVN",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Execute the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2.34246254e-05 4.64618206e-05 3.66044044e-03 2.64644623e-05\n",
      "  2.50637531e-05 1.46134138e-01 9.65267420e-04 8.57657194e-02\n",
      "  3.77222896e-03 5.04640400e-01]\n",
      " [6.64651394e-04 1.00016594e-04 8.95688415e-01 3.88681889e-04\n",
      "  7.82154202e-02 3.68058681e-05 2.18800694e-01 9.53674316e-07\n",
      "  4.83423471e-04 6.89923763e-05]\n",
      " [1.42812729e-03 9.86514807e-01 5.39124012e-04 6.19780123e-02\n",
      "  9.03305411e-03 8.35657120e-05 2.42772698e-03 1.67489052e-05\n",
      "  1.70677900e-04 1.12652779e-05]\n",
      " [3.39305401e-03 9.74074244e-01 1.54969096e-03 8.55717659e-02\n",
      "  1.68947279e-02 2.99155712e-04 5.56999445e-03 7.42971897e-05\n",
      "  5.62399626e-04 5.35547733e-05]\n",
      " [2.28496313e-01 3.64941359e-03 3.75311375e-01 3.46150398e-02\n",
      "  2.39878893e-01 1.92539692e-02 4.74475771e-01 4.44954634e-03\n",
      "  3.20627987e-02 1.02349520e-02]]\n"
     ]
    }
   ],
   "source": [
    "print(predY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JNLR8tcBOIVP"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 52us/sample - loss: 0.1172 - acc: 0.9547\n",
      "Test loss: 0.12, test accuracy: 95.5%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(testX, testY)\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Py-KwkmjOIVU"
   },
   "source": [
    "### Customize the learning rate to 0.001 in sgd optimizer and run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yLXUE9jWOIVV"
   },
   "outputs": [],
   "source": [
    "# Initialize the constructor\n",
    "model = Sequential()\n",
    "\n",
    "# Add an input layer \n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "\n",
    "# Add an BatchNormalization layer \n",
    "model.add(BatchNormalization())\n",
    "\n",
    "# Add one hidden layer \n",
    "model.add(Dense(8, activation='relu'))\n",
    "\n",
    "# Add an output layer \n",
    "model.add(Dense(10, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pJUqA5T4OIVc"
   },
   "outputs": [],
   "source": [
    "# setting up the optimization of our weights \n",
    "sgd = SGD(lr=0.001, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      " - 6s - loss: 0.2920 - acc: 0.8716 - val_loss: 0.1670 - val_acc: 0.9343\n",
      "Epoch 2/5\n",
      " - 7s - loss: 0.1601 - acc: 0.9384 - val_loss: 0.1355 - val_acc: 0.9468\n",
      "Epoch 3/5\n",
      " - 6s - loss: 0.1390 - acc: 0.9465 - val_loss: 0.1190 - val_acc: 0.9533\n",
      "Epoch 4/5\n",
      " - 7s - loss: 0.1262 - acc: 0.9512 - val_loss: 0.1090 - val_acc: 0.9571\n",
      "Epoch 5/5\n",
      " - 6s - loss: 0.1187 - acc: 0.9538 - val_loss: 0.1029 - val_acc: 0.9596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2793b0f07f0>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the fitting\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=16, validation_split=0.2, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "predY = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.9937754e-05 9.9793077e-04 3.6060810e-06 3.0852258e-03 6.5779686e-04\n",
      "  1.0416114e-01 2.8088689e-04 9.1257364e-02 2.2319257e-03 4.2867452e-01]\n",
      " [1.7076731e-05 2.2351742e-06 8.1740427e-01 1.7881393e-07 2.3253769e-02\n",
      "  6.3081682e-03 9.0756506e-02 1.2810826e-03 2.6643276e-05 1.1920929e-07]\n",
      " [6.8444610e-03 9.9980420e-01 1.8860728e-02 4.4019222e-03 4.9114227e-04\n",
      "  1.3819337e-04 1.6847253e-04 0.0000000e+00 1.4150143e-04 1.4901161e-07]\n",
      " [6.4820051e-03 9.9848580e-01 1.0795981e-02 6.7188740e-03 4.9722195e-04\n",
      "  7.7942014e-04 2.5951862e-04 3.8743019e-07 2.9662251e-04 1.0132790e-06]\n",
      " [2.4714074e-01 1.4955699e-03 3.0132943e-01 1.0731369e-02 6.9070429e-02\n",
      "  9.7457170e-03 4.7887471e-01 9.1305375e-03 9.8280609e-03 1.0453463e-03]]\n"
     ]
    }
   ],
   "source": [
    "print(predY[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predY[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 0s 42us/sample - loss: 0.1055 - acc: 0.9580\n",
      "Test loss: 0.11, test accuracy: 95.8%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(testX, testY)\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j9CSqKvpOIVk",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Build the Neural Network model with 3 Dense layers with 100,100,10 neurons respectively in each layer. Use cross entropy loss function and singmoid as activation in the hidden layers and softmax as activation function in the output layer. Use sgd optimizer with learning rate 0.03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GGAad54JOIVm"
   },
   "outputs": [],
   "source": [
    "# instantiate model\n",
    "model = Sequential()\n",
    "\n",
    "# we can think of this chunk as the input layer\n",
    "model.add(Flatten(input_shape=(28,28)))\n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('tanh'))\n",
    "\n",
    "# we can think of this chunk as the hidden layer    \n",
    "model.add(Dense(100))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "# we can think of this chunk as the output layer\n",
    "model.add(Dense(10))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MQ7oIymROIVp"
   },
   "outputs": [],
   "source": [
    "# setting up the optimization of our weights \n",
    "sgd = SGD(lr=0.03, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "model.compile(loss='binary_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nr2YsZV0OIV0",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Review model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h4ojW6-oOIV2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_3 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 100)               78500     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_2 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_3 (Ba (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 10)                1010      \n",
      "_________________________________________________________________\n",
      "batch_normalization_v1_4 (Ba (None, 10)                40        \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 90,450\n",
      "Trainable params: 90,030\n",
      "Non-trainable params: 420\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([[-0.04120455,  0.04240797,  0.0215907 , ...,  0.00849964,\n",
       "          0.02471569, -0.00324752],\n",
       "        [ 0.07545625, -0.01055136, -0.01443462, ...,  0.06167531,\n",
       "          0.00573019, -0.04984713],\n",
       "        [-0.06864479,  0.05955055, -0.0502913 , ..., -0.05240409,\n",
       "         -0.03258058, -0.01517817],\n",
       "        ...,\n",
       "        [-0.07830998,  0.07357807, -0.00642342, ..., -0.03559029,\n",
       "          0.0057878 , -0.04576533],\n",
       "        [-0.0611282 , -0.02540643,  0.04570118, ..., -0.04515198,\n",
       "          0.06731704, -0.05760349],\n",
       "        [-0.05877699,  0.0466857 ,  0.07206866, ..., -0.00632183,\n",
       "          0.01234698,  0.05151397]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([[ 6.57631457e-02, -1.83419734e-02, -1.52132660e-01, ...,\n",
       "         -6.49369583e-02,  1.34059161e-01, -2.33185142e-02],\n",
       "        [ 1.50188804e-04, -1.21948637e-01,  1.03915185e-01, ...,\n",
       "          4.49489057e-02, -1.44132808e-01, -1.04110636e-01],\n",
       "        [ 1.12596542e-01,  8.22418034e-02, -1.06905088e-01, ...,\n",
       "         -1.31388009e-02,  1.18910283e-01,  6.31522089e-02],\n",
       "        ...,\n",
       "        [ 8.37571621e-02, -1.83826536e-02, -8.44300762e-02, ...,\n",
       "         -3.39914113e-02,  2.61375755e-02, -1.29485577e-01],\n",
       "        [-1.64277360e-01, -3.94626707e-02, -9.40250829e-02, ...,\n",
       "         -7.01483414e-02, -1.35597318e-01,  7.44211674e-03],\n",
       "        [ 5.65378368e-03, -5.91816008e-03, -1.00024171e-01, ...,\n",
       "         -2.59767473e-03,  6.26316816e-02, -8.64440054e-02]], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "        1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.],\n",
       "       dtype=float32),\n",
       " array([[ 0.1627172 ,  0.18373087,  0.23014101,  0.21904704,  0.00500976,\n",
       "          0.13228244,  0.20841703, -0.00161207, -0.05280714,  0.01377493],\n",
       "        [-0.09067965, -0.09326638, -0.0729727 ,  0.13358536,  0.07190764,\n",
       "         -0.14022973,  0.18049482, -0.05553876,  0.03493893,  0.1945031 ],\n",
       "        [-0.20980886,  0.18906698,  0.05870932, -0.13039525, -0.2294819 ,\n",
       "          0.21415272,  0.20888641, -0.21693417,  0.15713036, -0.0066618 ],\n",
       "        [-0.0317995 ,  0.08858883,  0.20667982, -0.1147461 , -0.06381147,\n",
       "         -0.14682195, -0.2090008 , -0.08382517,  0.18986458,  0.07328102],\n",
       "        [ 0.21523625, -0.15233418,  0.04789364,  0.20822039,  0.1056264 ,\n",
       "          0.03101853,  0.10476384, -0.18612076, -0.06610775,  0.03960657],\n",
       "        [-0.13534409,  0.08950314,  0.12119582,  0.17749888,  0.01116592,\n",
       "          0.07580298,  0.08873627,  0.10475007, -0.20841835, -0.03326516],\n",
       "        [ 0.05526903,  0.03090388,  0.2203801 ,  0.10053524,  0.02820489,\n",
       "          0.01280499,  0.14984885, -0.0704681 , -0.00180696,  0.16250986],\n",
       "        [-0.06784934, -0.1400848 , -0.185663  , -0.22909006, -0.2271722 ,\n",
       "         -0.05425143,  0.06270766, -0.21946055,  0.12125701,  0.08134162],\n",
       "        [-0.00538473, -0.15110222,  0.21847457, -0.09526923, -0.0218391 ,\n",
       "         -0.0465856 , -0.13881892,  0.1599733 ,  0.19101232, -0.10081789],\n",
       "        [-0.04196613, -0.08012919,  0.17656946,  0.08109266,  0.04466295,\n",
       "         -0.18635847,  0.20557514,  0.05192012, -0.17649764, -0.13186738],\n",
       "        [ 0.00251874, -0.11663029,  0.03538272, -0.17629752,  0.05954853,\n",
       "         -0.05764055,  0.04485294,  0.20021236,  0.11308241, -0.20561011],\n",
       "        [ 0.02601457, -0.2105745 , -0.13297346,  0.00751781, -0.22945283,\n",
       "          0.12704194, -0.16279104,  0.15840453,  0.19692424, -0.10244019],\n",
       "        [-0.18511797, -0.0342949 ,  0.07948929,  0.09974656,  0.19408932,\n",
       "          0.17520782,  0.2123118 ,  0.0964624 , -0.21757212, -0.14757088],\n",
       "        [-0.04248916,  0.02445295, -0.16385497,  0.08937362, -0.11457026,\n",
       "         -0.14985949,  0.07052365,  0.16531548, -0.1208939 , -0.20922346],\n",
       "        [-0.08807214,  0.2040593 , -0.19078496, -0.09454641, -0.12758066,\n",
       "          0.11329007,  0.23155707,  0.01501174, -0.08614725,  0.16596997],\n",
       "        [-0.1958176 , -0.13997343, -0.13434777,  0.05142102, -0.18810602,\n",
       "          0.03192183,  0.20097983, -0.01470432,  0.00383113,  0.09477243],\n",
       "        [-0.0067993 , -0.18427844,  0.08105236,  0.111974  , -0.03450215,\n",
       "         -0.16390063, -0.15381673, -0.13031277, -0.20953885,  0.2229391 ],\n",
       "        [ 0.16896397,  0.09050792, -0.14332125, -0.04685205,  0.09856892,\n",
       "          0.04344067, -0.16022457, -0.12878495,  0.028685  ,  0.09359714],\n",
       "        [ 0.0488241 ,  0.11878681,  0.03086391,  0.02402231, -0.20001686,\n",
       "          0.11210585,  0.16795316,  0.22119465,  0.09555331,  0.03123164],\n",
       "        [-0.12993291,  0.23339656, -0.21014757,  0.16484177, -0.1401304 ,\n",
       "          0.21368387, -0.08715437,  0.2073986 , -0.02802844,  0.00073072],\n",
       "        [ 0.14194238, -0.20571145,  0.22714135,  0.02402359, -0.01899488,\n",
       "         -0.00377461,  0.04396111, -0.01441823, -0.00719196, -0.00769594],\n",
       "        [-0.05642611, -0.20443693,  0.14418972,  0.123981  , -0.19415325,\n",
       "         -0.10126168,  0.01022299, -0.16045004,  0.0475688 , -0.03289254],\n",
       "        [-0.10105899,  0.06948912, -0.17958926,  0.06957489,  0.01759169,\n",
       "          0.01311192,  0.18091595, -0.17228231,  0.10979229,  0.13509369],\n",
       "        [ 0.03759789,  0.21313879, -0.15093383,  0.12473673,  0.07989693,\n",
       "          0.21260753,  0.16386366, -0.23341933, -0.03424162,  0.00385028],\n",
       "        [ 0.19084948,  0.08969468,  0.07035628, -0.01340775, -0.20095149,\n",
       "          0.16266593, -0.11828111,  0.0616287 , -0.12811014, -0.2200177 ],\n",
       "        [-0.17841607, -0.08749332, -0.06685831, -0.09247167, -0.1952325 ,\n",
       "          0.05008131, -0.20660812, -0.07106723, -0.12452012, -0.21777949],\n",
       "        [ 0.11641151, -0.00112016, -0.11971372, -0.071035  , -0.21399814,\n",
       "         -0.11108012,  0.00242609, -0.13250434, -0.21841627, -0.10828458],\n",
       "        [ 0.0237169 , -0.07361962, -0.02924839,  0.1954427 ,  0.01294976,\n",
       "          0.01703882, -0.06350471, -0.05223706,  0.09170899,  0.21227676],\n",
       "        [-0.16332938,  0.1511164 , -0.07084039,  0.05733612, -0.00257331,\n",
       "         -0.18099262,  0.03215891,  0.1564691 ,  0.16440499, -0.16408122],\n",
       "        [ 0.0245474 ,  0.19281948, -0.01628977,  0.07155797,  0.1721043 ,\n",
       "          0.18018785, -0.16063055, -0.13363625, -0.10238935,  0.0203599 ],\n",
       "        [-0.2255845 , -0.00535126,  0.14348549,  0.02112558,  0.00720465,\n",
       "         -0.11749593,  0.08036533,  0.02012542, -0.04478611, -0.01884794],\n",
       "        [ 0.18622026,  0.06054696,  0.12093198, -0.00381643,  0.17334795,\n",
       "         -0.2129856 ,  0.01945087, -0.22659092, -0.04807384, -0.15660359],\n",
       "        [ 0.20665872,  0.05800727,  0.03032291, -0.10813357, -0.02437271,\n",
       "         -0.04307126, -0.01771653,  0.21235478, -0.22827761, -0.02544872],\n",
       "        [-0.21180224,  0.22802314, -0.04443008, -0.02774981, -0.22545995,\n",
       "          0.21296495,  0.08947185,  0.14168027,  0.21170652, -0.15132377],\n",
       "        [-0.18070658,  0.22138861,  0.05087829,  0.10164505, -0.05661209,\n",
       "         -0.06779672, -0.15331486,  0.19448557, -0.15005988, -0.18126641],\n",
       "        [ 0.20108402,  0.09929314,  0.073917  ,  0.16287372,  0.14868882,\n",
       "          0.1331453 , -0.14933255,  0.12868235,  0.18254843, -0.06228465],\n",
       "        [-0.22090206, -0.1215141 , -0.16608427,  0.09567443, -0.02055869,\n",
       "          0.13627014,  0.10003272,  0.05812216,  0.0192478 , -0.11816813],\n",
       "        [ 0.02231774,  0.07649162,  0.07393718,  0.18816426,  0.06484282,\n",
       "          0.00095557,  0.05988339, -0.04107687,  0.21000186,  0.03992808],\n",
       "        [-0.0187045 ,  0.09056348, -0.04724284, -0.12166032, -0.13521023,\n",
       "          0.16297367,  0.17190143, -0.10975689, -0.18336892,  0.05870014],\n",
       "        [-0.11890698, -0.12681028, -0.20333882,  0.05482608, -0.18847653,\n",
       "         -0.00141262, -0.1563558 ,  0.17336154, -0.12984198,  0.14405   ],\n",
       "        [ 0.02743196, -0.10914171, -0.17849642,  0.06866777,  0.22211188,\n",
       "         -0.00163791, -0.16534165,  0.02849001, -0.04534996,  0.1697841 ],\n",
       "        [-0.10193838, -0.10367118,  0.08082828, -0.22327954,  0.16818851,\n",
       "          0.19025841, -0.03976588,  0.07439893, -0.07992744,  0.14369938],\n",
       "        [-0.00920416,  0.08771655,  0.00603504,  0.12238207,  0.06177559,\n",
       "          0.06204829, -0.12805468, -0.03717375,  0.18752936,  0.14176556],\n",
       "        [-0.07522528,  0.1986559 , -0.15417042,  0.13303989,  0.16953549,\n",
       "          0.16988945, -0.11279409, -0.15437557,  0.22193831, -0.22786254],\n",
       "        [ 0.09502584, -0.10072467, -0.0810391 , -0.21058574, -0.00245433,\n",
       "         -0.18150423,  0.16677362, -0.00661181,  0.02204707,  0.2106303 ],\n",
       "        [-0.2132408 ,  0.03398064,  0.06354141, -0.11982497,  0.01717463,\n",
       "          0.16601005,  0.17497501,  0.16066697, -0.1803741 ,  0.19171304],\n",
       "        [-0.1740549 , -0.00174621, -0.21244225,  0.18655246,  0.04808426,\n",
       "          0.06057063,  0.03863797, -0.1764468 , -0.02031529,  0.11280522],\n",
       "        [-0.06289576,  0.13118032,  0.00319284,  0.16816932, -0.01013623,\n",
       "          0.08270919, -0.07313836,  0.22121382, -0.05939299,  0.06769371],\n",
       "        [-0.03341746, -0.03617993, -0.22751676, -0.02904928,  0.03167516,\n",
       "          0.22316316, -0.1687288 , -0.08391371, -0.21435507, -0.04423614],\n",
       "        [ 0.17349201, -0.09974755, -0.11558574, -0.21712193, -0.14296436,\n",
       "         -0.01065359, -0.07184367, -0.14790018,  0.16460168,  0.18654472],\n",
       "        [-0.04552357, -0.01385099, -0.0906131 ,  0.14793119, -0.07178448,\n",
       "          0.08725217,  0.06438705,  0.1343123 ,  0.14327618, -0.0717832 ],\n",
       "        [-0.01283166, -0.22962178,  0.05502966,  0.03163305, -0.11926681,\n",
       "         -0.00408609, -0.13080636, -0.01485243,  0.01766285, -0.20228113],\n",
       "        [ 0.03512144,  0.1752719 , -0.2202797 ,  0.16562903,  0.05030516,\n",
       "          0.09234911,  0.10741094,  0.12254339, -0.1859981 , -0.21445735],\n",
       "        [ 0.10014796,  0.1804089 , -0.12496158, -0.19713995, -0.06953736,\n",
       "          0.13921726,  0.04041842, -0.17636117,  0.20037434,  0.13352239],\n",
       "        [-0.06138426,  0.19658387,  0.03404611,  0.15878823, -0.17561318,\n",
       "          0.12769714,  0.10087112, -0.09369463,  0.22216916, -0.06308904],\n",
       "        [ 0.06368294, -0.19713384, -0.16866934, -0.03324841, -0.13574924,\n",
       "         -0.13567391, -0.01782995,  0.16289487, -0.21775994, -0.12341037],\n",
       "        [ 0.05366781,  0.0198206 ,  0.1251185 ,  0.0888654 ,  0.04677254,\n",
       "         -0.11591449,  0.10613486,  0.18455061,  0.02202195,  0.13999313],\n",
       "        [-0.04498006,  0.19346908,  0.1819869 , -0.23095866,  0.02709883,\n",
       "         -0.10446475, -0.2286053 ,  0.17620307,  0.11012635, -0.22371158],\n",
       "        [ 0.03510553,  0.22024679, -0.0590222 , -0.12264529,  0.06593013,\n",
       "          0.15331766,  0.02325645, -0.05197357, -0.19997236, -0.18185014],\n",
       "        [-0.0501523 , -0.00103402, -0.12339055,  0.04913855, -0.11774416,\n",
       "         -0.02017725, -0.03432988, -0.03099827,  0.02692983, -0.22196525],\n",
       "        [-0.00333299, -0.10205549,  0.17594266, -0.05667719,  0.04278973,\n",
       "         -0.09243949, -0.10448058, -0.05321835,  0.03428367, -0.10589741],\n",
       "        [ 0.15968803, -0.16624464,  0.1656025 , -0.01036793,  0.04205456,\n",
       "         -0.19890264, -0.17037094, -0.13910796, -0.0827838 , -0.18048173],\n",
       "        [-0.11135525,  0.15707496,  0.18450737,  0.07133675, -0.22600508,\n",
       "          0.20412266, -0.23240903,  0.21427026, -0.1630214 ,  0.1638098 ],\n",
       "        [-0.01033904, -0.2285804 ,  0.09795097,  0.09105405, -0.02247182,\n",
       "          0.05075926,  0.08054492,  0.0069018 , -0.02441625,  0.16424435],\n",
       "        [ 0.12529758, -0.09792155,  0.1437687 ,  0.00877991,  0.16211656,\n",
       "         -0.19512247, -0.08684318, -0.14293686, -0.06283568, -0.20059562],\n",
       "        [ 0.00497423,  0.08772168, -0.11364765, -0.00695203,  0.10049722,\n",
       "         -0.08213833,  0.17281875, -0.02852608,  0.0923588 , -0.20020539],\n",
       "        [ 0.00592485, -0.14768034, -0.12041114, -0.19640851, -0.20999478,\n",
       "         -0.17284141,  0.16874078, -0.22661486,  0.19188353,  0.19346818],\n",
       "        [ 0.04550475,  0.19400781,  0.03933352, -0.01067352, -0.03715749,\n",
       "         -0.1314099 , -0.06728043,  0.02608779,  0.07780164, -0.13657385],\n",
       "        [ 0.00116616,  0.17365545, -0.2146391 , -0.07319181,  0.14003384,\n",
       "         -0.01007025, -0.16895264, -0.09174156, -0.18544666,  0.16099983],\n",
       "        [-0.09260482, -0.07369773, -0.21006489,  0.1998193 ,  0.06638226,\n",
       "          0.04301947,  0.11990038, -0.10162489, -0.16276169,  0.07104078],\n",
       "        [ 0.13790464,  0.18464947,  0.1135008 ,  0.15237167, -0.01051243,\n",
       "         -0.10814694,  0.02435717,  0.16609624,  0.194767  , -0.04478066],\n",
       "        [-0.14862305, -0.15539089,  0.22151095,  0.18376255, -0.22165126,\n",
       "          0.14781064, -0.15684915,  0.03137001,  0.10461226,  0.1174491 ],\n",
       "        [ 0.20653644,  0.16673148, -0.06418659,  0.01088612, -0.11910371,\n",
       "          0.01641044, -0.01531549, -0.01516393,  0.01797935,  0.16072571],\n",
       "        [ 0.10615304,  0.15888005, -0.03027061, -0.09145124,  0.16651443,\n",
       "          0.19031182,  0.14346981, -0.0118845 , -0.18399976, -0.2120023 ],\n",
       "        [ 0.12629277,  0.1808759 ,  0.19390157, -0.16330183, -0.12704894,\n",
       "          0.21917343,  0.0260326 , -0.14111665,  0.04186413, -0.03435043],\n",
       "        [ 0.15966123, -0.2141569 ,  0.04641744, -0.211157  , -0.05790883,\n",
       "          0.18820748, -0.01771268,  0.12939325, -0.22837415, -0.14801583],\n",
       "        [ 0.08104643, -0.03515938, -0.05471911, -0.12594336, -0.06082286,\n",
       "          0.02182484, -0.01151928,  0.19767979, -0.00348027,  0.15532279],\n",
       "        [ 0.07118618, -0.07028751, -0.18982744,  0.17392343,  0.16197088,\n",
       "          0.01956698,  0.02758604, -0.19101949,  0.09399521, -0.03287344],\n",
       "        [-0.02044347,  0.17171842, -0.11530187, -0.09600925,  0.0274632 ,\n",
       "          0.0954439 ,  0.12197271,  0.12287748, -0.04140674, -0.14029211],\n",
       "        [ 0.17034376,  0.20065504,  0.0650171 ,  0.0294013 , -0.12619244,\n",
       "         -0.14359865,  0.15112048,  0.16439939, -0.21329476, -0.10892633],\n",
       "        [ 0.17263076, -0.12454835,  0.15597498,  0.06799117,  0.02994648,\n",
       "         -0.05828987,  0.01364641,  0.159168  ,  0.18767837, -0.00992966],\n",
       "        [ 0.09402165,  0.11050558, -0.10316005,  0.01979932,  0.04280609,\n",
       "          0.08122519,  0.08250761,  0.10578772, -0.06552956,  0.06629986],\n",
       "        [ 0.05252126,  0.17972663, -0.00801317, -0.1589166 , -0.10495733,\n",
       "         -0.10435556, -0.07290894,  0.08585414, -0.13596462, -0.1337181 ],\n",
       "        [-0.22389755,  0.16394857,  0.00926726,  0.04292822, -0.0655394 ,\n",
       "         -0.19997826, -0.05423105,  0.15667331, -0.12575439, -0.21870126],\n",
       "        [-0.11374549,  0.0560663 , -0.17019704, -0.12684354, -0.21750453,\n",
       "          0.19348624,  0.11917108, -0.21793546, -0.0518024 , -0.18563287],\n",
       "        [-0.12343253, -0.03524479, -0.1815549 ,  0.01163381, -0.1591439 ,\n",
       "         -0.01527947,  0.04227957, -0.21547613,  0.17990297, -0.2026513 ],\n",
       "        [ 0.17451033, -0.16316445, -0.1132234 ,  0.01965165, -0.02218856,\n",
       "         -0.22862583,  0.23249766,  0.14470121,  0.03926161, -0.15625028],\n",
       "        [-0.21891335, -0.06529763, -0.069235  , -0.01943099, -0.21230009,\n",
       "         -0.01553416, -0.1145177 , -0.04243331, -0.2329741 ,  0.00653012],\n",
       "        [ 0.1058439 , -0.22090216,  0.13276455, -0.0734328 ,  0.08794424,\n",
       "          0.04544505,  0.19313762,  0.10727635, -0.10845481, -0.16498983],\n",
       "        [-0.10283621, -0.14232641,  0.18938866, -0.2168272 ,  0.09791499,\n",
       "          0.05541304, -0.04141682,  0.11025435, -0.04346572, -0.00310765],\n",
       "        [-0.16514423,  0.03217652,  0.2277042 , -0.18804894,  0.00809102,\n",
       "         -0.06719251, -0.16223812,  0.20115244,  0.22773737,  0.16808078],\n",
       "        [-0.20098545,  0.1731827 ,  0.11392137,  0.20009625, -0.0968481 ,\n",
       "          0.00944522,  0.04940048,  0.08534342, -0.08554593,  0.22348234],\n",
       "        [ 0.20372069, -0.08189471,  0.08205062, -0.03567745,  0.1473904 ,\n",
       "          0.02287853, -0.07238869,  0.18988824, -0.17890736, -0.07137884],\n",
       "        [-0.09371395,  0.08518717, -0.11842588,  0.18450975,  0.00907865,\n",
       "         -0.14254835, -0.2075256 , -0.08697079,  0.2227217 , -0.15508084],\n",
       "        [-0.14779656,  0.2113781 ,  0.08923852,  0.10435802, -0.19908589,\n",
       "         -0.0800603 , -0.15059188,  0.03890491, -0.00656003, -0.23033641],\n",
       "        [-0.10173008,  0.11851487, -0.03062426,  0.20055899, -0.11002394,\n",
       "         -0.00759549, -0.09776855,  0.0260947 , -0.2231748 , -0.14923255],\n",
       "        [ 0.20177391, -0.22019595,  0.10384679,  0.07397547, -0.22906925,\n",
       "          0.1828351 ,  0.12133971, -0.01891799,  0.1651561 ,  0.11963814],\n",
       "        [ 0.12872255,  0.00416178,  0.18520388,  0.20178333,  0.11417568,\n",
       "          0.10373649,  0.05818173, -0.0235436 ,  0.07762086,  0.13479656],\n",
       "        [ 0.08618411, -0.15724874, -0.14581609, -0.08019863,  0.05888283,\n",
       "          0.21682853,  0.17961675,  0.07827252, -0.13819705, -0.16109717],\n",
       "        [ 0.0422661 , -0.21744177,  0.01966646,  0.21593106,  0.22405285,\n",
       "         -0.04276356, -0.03365494,  0.16165501,  0.21065155,  0.03901958]],\n",
       "       dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], dtype=float32),\n",
       " array([1., 1., 1., 1., 1., 1., 1., 1., 1., 1.], dtype=float32)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model output shape\n",
    "model.output_shape\n",
    "\n",
    "# Model summary\n",
    "model.summary()\n",
    "\n",
    "# Model config\n",
    "model.get_config()\n",
    "\n",
    "# List all weight tensors \n",
    "model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gfFGmbZLOIV5",
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Run the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/5\n",
      " - 9s - loss: 0.0723 - acc: 0.9726 - val_loss: 0.0663 - val_acc: 0.9733\n",
      "Epoch 2/5\n",
      " - 10s - loss: 0.0688 - acc: 0.9739 - val_loss: 0.0607 - val_acc: 0.9763\n",
      "Epoch 3/5\n",
      " - 10s - loss: 0.0670 - acc: 0.9745 - val_loss: 0.0621 - val_acc: 0.9761\n",
      "Epoch 4/5\n",
      " - 10s - loss: 0.0641 - acc: 0.9757 - val_loss: 0.0594 - val_acc: 0.9769\n",
      "Epoch 5/5\n",
      " - 10s - loss: 0.0631 - acc: 0.9759 - val_loss: 0.0679 - val_acc: 0.9742\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2793c043320>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# running the fitting\n",
    "model.fit(trainX, trainY, epochs=5, batch_size=16, validation_split=0.2, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.02480340e-04, 1.21778845e-04, 6.96166011e-04, 5.22965973e-04,\n",
       "       2.47177260e-04, 1.90412663e-02, 3.93057242e-03, 1.16786063e-02,\n",
       "       7.22376746e-04, 9.62836623e-01], dtype=float32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(predictions[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 1.], dtype=float32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testY[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bIkbMEN5OIV7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 63us/sample - loss: 0.0721 - acc: 0.9719\n",
      "Test loss: 0.07, test accuracy: 97.2%\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(testX, testY)\n",
    "print(\"Test loss: {0:.2f}, test accuracy: {1:.01%}\".format(test_loss, test_acc))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "R6_ExternalLab_AIML.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
